# VulnSC 复现步骤（仅基准模型训练与评估）

> 本文档默认你**不重跑数据增强**，直接使用仓库已提供的增强数据：`data/enhance/devign/*`。

## 1. 复现目标与范围

本复现仅覆盖：
1. 基准模型训练（CodeBERT / GraphCodeBERT / UniXcoder / LineVul）
2. 在测试集评估并输出指标
3. 对比“非增强 vs 增强（4 种 prompt）”

不覆盖：
- 代码检索
- LLM 摘要生成
- 增强样本构造

---

## 2. 环境准备

## 2.1 建议环境
- Linux
- Python 3.10+（建议 3.10 或 3.11）
- CUDA + PyTorch GPU 版本
- 至少 1 张可用 GPU（脚本默认按 4 张卡写了设备号）

说明（你当前是 CUDA 13.0）：
- PyTorch 官方 wheel 目前通常按 CUDA 12.x 提供（如 cu124/cu126）。
- 只要 NVIDIA 驱动足够新，安装 cu12x 版 PyTorch 一般可在 CUDA 13.0 驱动环境正常运行。

## 2.2 安装依赖（Conda 方案）

在仓库根目录执行：

```bash
cd /disk1/hs/vulnsc

# 1) 创建并激活 conda 环境
conda create -n vulnsc python=3.10 -y
conda activate vulnsc

# 2) 安装 PyTorch（示例为 CUDA 12.4）
pip install --upgrade pip
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# 3) 安装其余依赖
pip install transformers scikit-learn pandas numpy tqdm tensorboard tokenizers captum matplotlib pygments
pip install modelscope
```

说明：
- 如果你的 CUDA 版本不是 12.4，请改用对应的 PyTorch 安装源。
- `LineVul` 依赖 `captum`，即使不做解释性分析，也建议安装，避免导入报错。

## 2.3 基础模型是否要下载到本地？下载到哪里？

建议提前下载到本地（尤其是内网或网络不稳定环境），但**不是必须**。

默认行为：
- `transformers` 会自动从 HuggingFace 下载并缓存模型。
- 默认缓存目录通常在 `~/.cache/huggingface/`。

推荐做法（可复现、便于迁移）：
1. 统一设置缓存目录到项目外部（例如 `/disk1/hs/hf_cache`）。
2. 或者把模型完整下载到指定目录，再在脚本里把 `--model_name_or_path` 和 `--tokenizer_name` 改为本地路径。

示例（仅设置缓存目录，不改脚本参数）：

```bash
export HF_HOME=/disk1/hs/hf_cache
export TRANSFORMERS_CACHE=/disk1/hs/hf_cache/transformers
```

如果你希望完全离线并固定本地模型路径，示例目录可用：
- `/disk1/hs/pretrained/microsoft/codebert-base`
- `/disk1/hs/pretrained/microsoft/graphcodebert-base`

对应脚本改动建议：
- 把 `--model_name_or_path=microsoft/codebert-base` 改为本地目录。
- 把 `--tokenizer_name=microsoft/codebert-base` 改为本地目录。
- GraphCodeBERT、UniXcoder、LineVul 同理。

结论：
- **在线环境**：可不改脚本，首次运行自动下载。
- **离线/集群复现**：建议改成“本地路径 + 固定缓存目录”。

## 2.4 用 ModelScope 下载到 `/disk1/hs/model`

仓库已提供下载脚本：`scripts/download_models_modelscope.py`

执行：

```bash
cd /disk1/hs/vulnsc
conda activate vulnsc
python scripts/download_models_modelscope.py --model-root /disk1/hs/model
```

下载后目标目录应包含：
- `/disk1/hs/model/codebert-base`
- `/disk1/hs/model/graphcodebert-base`
- `/disk1/hs/model/unixcoder-base`

快速检查：

```bash
ls -lah /disk1/hs/model
```

---

## 3. 数据检查（非常重要）

脚本默认会访问以下结构：

- `data/enhance/devign/<llm_name>/<prompt_id>/train.jsonl`
- `data/enhance/devign/<llm_name>/<prompt_id>/valid.jsonl`
- `data/enhance/devign/<llm_name>/<prompt_id>/test.jsonl`

其中：
- `<llm_name>` ∈ `{codellama, deepseek, gpt4o, mixtral}`
- `<prompt_id>` ∈ `{0,1,2,3}`

建议先检查缺失文件：

```bash
cd /disk1/hs/vulnsc
for llm in codellama deepseek gpt4o mixtral; do
  for i in 0 1 2 3; do
    for split in train valid test; do
      f="data/enhance/devign/$llm/$i/$split.jsonl"
      [[ -f "$f" ]] || echo "MISSING: $f"
    done
  done
done
```

如果有缺失，直接跑整脚本会在对应阶段失败，需要先补齐该 split。

---

## 4. 一键复现实验（按增强来源分组）

进入 `models` 目录后，执行任意一个脚本：

```bash
cd /disk1/hs/vulnsc/models
bash run_devign_codellama.sh
bash run_devign_deepseek.sh
bash run_devign_gpt4o.sh
bash run_devign_mixtral.sh
```

说明：
- 这四个脚本已改为默认本地模型模式：
  - `VULNSC_MODEL_ROOT=/disk1/hs/model`
  - `TRANSFORMERS_OFFLINE=1`
  - `HF_DATASETS_OFFLINE=1`
- 即优先从 `/disk1/hs/model` 读取，不再在线下载。

每个脚本都会自动串行运行四个 baseline：
- CodeBERT
- GraphCodeBERT
- UniXcoder
- LineVul

并完成：
- 非增强训练/测试
- 增强训练/测试（basic/behavior/oneshot/cot）

---

## 5. 单模型最小复现（推荐先做）

为减少排障成本，建议先跑一组最小实验（例如 CodeBERT + deepseek + basic）：

```bash
cd /disk1/hs/vulnsc/models/CodeBERT

CUDA_VISIBLE_DEVICES=0 python run.py \
  --enhance \
  --output_dir=./saved_models \
  --model_type=roberta \
  --tokenizer_name=microsoft/codebert-base \
  --model_name_or_path=microsoft/codebert-base \
  --do_train \
  --do_eval \
  --do_test \
  --train_data_file=../../data/enhance/devign/deepseek/0/train.jsonl \
  --eval_data_file=../../data/enhance/devign/deepseek/0/valid.jsonl \
  --test_data_file=../../data/enhance/devign/deepseek/0/test.jsonl \
  --metric=eval_f1 \
  --epoch 3 \
  --block_size 500 \
  --train_batch_size 16 \
  --eval_batch_size 64 \
  --learning_rate 2e-5 \
  --max_grad_norm 1.0 \
  --evaluate_during_training \
  --seed 123457

python evaluator.py \
  -a ../../data/enhance/devign/deepseek/0/test.jsonl \
  -p ./saved_models/predictions.txt \
  -m cb -e enhance -t basic -s 123457
```

---

## 6. 结果文件与对比方式

运行后重点查看：

- `models/cb_result.csv`
- `models/gcb_result.csv`
- `models/ux_result.csv`
- `models/lv_result.csv`

时间开销文件：
- `models/cb_time.csv`
- `models/gcb_time.csv`
- `models/ux_time.csv`
- `models/lv_time.csv`

建议对比维度：
1. 同一模型下：`none-enhance` vs `enhance`
2. 同一模型+增强下：`basic/behavior/oneshot/cot`
3. 同一数据版本下：四个 baseline 横向对比

---

## 7. 一个 baseline 的完整流程（以 CodeBERT 为例）

一次完整实验链路如下：

1. **读数据**：`run.py` 读取 `train/valid/test.jsonl`。
2. **选输入字段**：
  - 不加 `--enhance`：使用 `func`
  - 加 `--enhance`：使用 `func_en`
3. **编码**：Tokenizer 做分词、截断（`--block_size`）、padding。
4. **训练**：按 `--epoch` 和学习率训练，训练中在验证集评估。
5. **保存最优**：按 `--metric`（常用 `eval_f1`）保存最佳权重到 `saved_models/checkpoint-best-per/model.bin`。
6. **测试**：加载最佳权重，对测试集推理，输出 `saved_models/predictions.txt`。
7. **评估与落盘**：`evaluator.py` 读取 `predictions.txt + test.jsonl`，输出指标并追加到 `models/cb_result.csv`。

同样流程适用于 GraphCodeBERT / UniXcoder，仅模型骨干不同。

---

## 8. 为什么 LineVul 目录文件更多？

`LineVul` 不仅做函数级分类，还集成了“行级解释/定位”能力，因此目录里有更多辅助组件：

- `linevul_main.py` / `linevul_model.py`：训练、评估与模型定义。
- `train_bpe_tokenizer.py`、`train_word_level_tokenizer.py`：可训练自定义 tokenizer。
- `bpe_tokenizer/`、`word_level_tokenizer/`：Tokenizer 词表与配置。
- `ifa_records/`：解释方法（如 saliency、deeplift 等）的结果记录。
- `results/`：LineVul 结果说明。
- `train_logs/`：训练日志。
- `saved_models/`：模型权重。

而 CodeBERT / GraphCodeBERT / UniXcoder 这里主要只保留了最小实验必需内容，所以目录看起来更“轻”，核心输出集中在 `saved_models/` 和上层 `*_result.csv` / `*_time.csv`。

---

## 9. VulnSC 与谁进行对比？

按论文设定，VulnSC 主要与两类方法对比：

1. **传统深度学习漏洞检测基线**：CodeBERT、GraphCodeBERT、UniXcoder、LineVul。
2. **现有 LLM 漏洞检测方法**：LLM4Vuln、Avishree、GRACE（论文报告中对比）。

本仓库当前直接可复现的是第 1 类（四个 baseline + 增强/非增强对照）。

---

## 10. 常见问题与处理

1. **GPU 不匹配**
   - 脚本里固定了 `CUDA_VISIBLE_DEVICES=0/1/2/3`。
   - 单卡机器请统一改成你可用的设备号。

2. **下载预训练模型失败**
   - 需要可访问 HuggingFace，或提前离线缓存模型。

3. **`train.jsonl/valid.jsonl/test.jsonl` 缺失**
   - 先做第 3 节的数据检查。
   - 缺失 split 会导致对应命令失败。

4. **LineVul 参数差异**
   - `LineVul` 用 `--enhance=enhance|none-enhance`（字符串），与其他三个模型的 `--enhance`（bool 开关）不同。

---

## 11. 推荐复现顺序

1. 先跑单模型最小复现（第 5 节）。
2. 再跑一个完整脚本（如 `run_devign_deepseek.sh`）。
3. 最后批量跑其余三组脚本并汇总 CSV。

这样最稳，且便于快速定位环境与数据问题。
