# VulnSC 论文核心、实验流程与源码解读

> 本文档基于当前仓库代码实现（`/disk1/hs/vulnsc`）整理，目标是把“论文方法”与“代码落地”一一对应。

## 1. 论文核心痛点与方法主线

### 1.1 论文要解决的问题
主流深度学习漏洞检测器（如 CodeBERT/LineVul）常用函数级输入，扩展性高，但对跨函数漏洞（如资源释放链路、跨函数参数传播）易漏检。

### 1.2 VulnSC 的核心思想
VulnSC（Vulnerability Semantic Completion）不把被调函数原文全部拼接给检测模型，而是：

1. 先检索被调函数调用链。
2. 用 LLM 对被调函数做语义摘要。
3. 采用自底向上汇总（先叶子后父节点）构造跨层语义。
4. 将摘要补充到原函数样本中，形成增强样本。
5. 用原有检测模型直接训练/测试。

### 1.3 与传统跨过程分析的取舍
- 不走高成本静态分析全流程（上下文敏感/全项目数据流）。
- 用“可压缩的语义注释”实现跨过程信息注入，提升可扩展性和工程可用性。

---

## 2. 仓库中的整体实现流

当前仓库分为两条链路：

- **数据增强链路**：`main.py` + `scripts/`
- **检测训练链路**：`models/`（四类 baseline）

### 2.1 数据增强链路（设计目标）
理论上对应：检索 -> 摘要 -> 语义补全 -> 划分数据集。

关键文件：
- `main.py`
- `scripts/code_retrieval.py`
- `scripts/code_summary.py`
- `scripts/code_enhance.py`

### 2.2 检测训练链路（实验主体）
关键目录：
- `models/CodeBERT`
- `models/GraphCodeBERT`
- `models/UniXcoder`
- `models/LineVul`
- `models/run_devign_*.sh`（实验编排脚本）

---

## 3. 数据增强代码解读（scripts）

## 3.1 `scripts/code_retrieval.py`：跨函数检索与调用链构建

核心职责：
- 从原始样本中拿 `project`、`commit_id`、`func`。
- 用 `ctags` 提取入口函数名。
- 对目标仓库执行 `git checkout <commit>`。
- 用 `cscope` 找 callee，层次遍历构建调用链（`layer` 字段）。
- 用 `ctags` + 行号提取被调函数源码字符串。
- 输出 `data/enhance/devign_source.jsonl`。

关键实现点：
- `retrieve_callee(...)`：按层扩展调用关系，写入 `layer/func_name/func_str/caller`。
- `extract_func(...)`：依赖 `ctags --fields=+ne-t` 的 `line:end` 范围取源码。

工程依赖：`git`、`find`、`cscope`、`ctags`。

## 3.2 `scripts/code_summary.py`：LLM 摘要与自底向上聚合

核心职责：
- 提供 4 类 prompt：基础、行为引导、单样本、CoT。
- 对调用图叶子节点先摘要，再把子摘要拼入父函数后继续摘要。
- 生成 `summary` 列表并写入 `devign_summary.jsonl`。

关键实现点：
- `generate_summary_for_callees(...)`：按 `layer` 逆序（bottom-up）生成摘要。
- `code_summarization(...)`：按 `ptid` 选择 prompt。

当前代码状态注意：
- 文件中写了 DeepSeek 风格 OpenAI 兼容客户端初始化（含占位 `api_key`）。
- 该实现是可运行模板，但需要你在本地安全配置真实 API Key（不要硬编码到仓库）。

## 3.3 `scripts/code_enhance.py`：摘要注入与数据集划分

核心职责：
- 从 `summary` 中取一层（`layer == 1`）摘要，拼接到原函数后，形成 `func_en`。
- 按标签分层后划分 train/valid/test（约 8:1:1）。

关键实现点：
- `instantiate_summary(...)`：生成增强样本。
- `split_enhance_dataset(...)`：写 `train.jsonl` / `valid.jsonl` / `test.jsonl`。

当前代码状态注意（很关键）：
- `main.py` 对 `instantiate_summary(...)` 的调用参数，与函数签名不一致。
- `split_enhance_dataset(...)` 默认读取 `devign_enhance.jsonl`，与 `instantiate_summary(...)` 当前输出命名/路径并不完全一致。
- 结论：仓库里“增强流程入口”与脚本版本存在漂移；但你当前已有增强数据，可直接绕过该链路做复现实验。

---

## 4. 基线模型代码解读（models）

## 4.1 共性：CodeBERT / GraphCodeBERT / UniXcoder

三个目录下 `run.py` 结构几乎一致：

1. 读取 jsonl 样本。
2. 根据 `--enhance` 选择 `func` 或 `func_en`。
3. 用 RoBERTa 系 tokenizer 编码（`block_size` 截断+padding）。
4. 二分类训练（保存 `checkpoint-best-per/model.bin`）。
5. `--do_test` 输出 `saved_models/predictions.txt`。
6. 用各自 `evaluator.py` 计算指标并写入汇总 CSV。

对应结果文件：
- CodeBERT: `models/cb_result.csv`
- GraphCodeBERT: `models/gcb_result.csv`
- UniXcoder: `models/ux_result.csv`

时间统计文件：
- `cb_time.csv`、`gcb_time.csv`、`ux_time.csv`

## 4.2 `LineVul` 路径特点

入口：`models/LineVul/linevul_main.py`

特点：
- `--enhance` 是字符串参数（如 `enhance` / `none-enhance`），不是 bool。
- 数据读取时根据该字符串选择 `func_en` 或 `func`。
- 训练时每 epoch 在验证集评估，按 `--metric`（如 `eval_f1`）保存最佳模型。
- 测试输出分类指标并写 `models/lv_result.csv`。
- 额外支持可解释性分析（Captum），但默认复现流程可不启用。

时间统计文件：
- `lv_time.csv`

---

## 5. 实验编排脚本解读

`models/run_devign_codellama.sh` / `deepseek.sh` / `gpt4o.sh` / `mixtral.sh` 的结构一致：

1. 在同一脚本里依次运行 **CodeBERT -> GraphCodeBERT -> UniXcoder -> LineVul**。
2. 每个模型都跑：
   - 原始输入（无增强）
   - 增强输入（prompt 0/1/2/3 对应 basic/behavior/oneshot/cot）
3. 每组都会执行 train + test + evaluator。

区别主要是：
- 数据路径前缀不同（`.../devign/<llm_name>/<prompt_id>/...`）
- `CUDA_VISIBLE_DEVICES` 设置不同（0/1/2/3）。

---

## 6. 论文实验流程如何映射到仓库

可按以下对应关系理解：

- 论文“跨过程检索” -> `scripts/code_retrieval.py`
- 论文“摘要生成（含多种 prompt）” -> `scripts/code_summary.py`
- 论文“语义补全样本” -> `scripts/code_enhance.py`
- 论文“检测性能评估” -> `models/*/run.py + evaluator.py`
- 论文“多模型、多prompt对比” -> `models/run_devign_*.sh`

---

## 7. 结论（面向你后续工作）

1. 你目前已有增强数据集，完全可以直接从 `models/` 复现实验主结果。
2. 复现重点应放在：统一环境、按脚本跑四个 baseline、收集 CSV 指标并对比。
3. 如果后续要重跑“数据增强阶段”，需要先修正 `main.py` 与 `scripts/code_enhance.py` 的接口漂移问题，再跑通整链。
